{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "098264d1-868b-4be6-b01e-781c06aceca2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Desafio DWE 2025 - Transformação Camada Gold\n",
    "**Esta é a camada que ficará disponível para a análise de dados. Nela serão aplicados:**\n",
    "- Gravação SCD do tipo 2 das tabelas de dimensão\n",
    "- Inserção das SKs nas tabelas dimensão e na relação com a fato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cc6cc38-4f22-47e6-a6a2-52a338f9264f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Transformação Camada Gold\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\")  \\\n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", \"128MB\") \\\n",
    "    .config(\"spark.sql.parquet.compression.codec\", \"snappy\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# Diretórios de trabalho \n",
    "sv_dim_path = '/mnt/desafio-dwe-25/lhdw/silver/dim'\n",
    "sv_fato_path = '/mnt/desafio-dwe-25/lhdw/silver/fato'\n",
    "\n",
    "gd_dim_path = '/mnt/desafio-dwe-25/lhdw/gold/dim'\n",
    "gd_fato_path = '/mnt/desafio-dwe-25/lhdw/gold/fato'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a72923b4-4e9a-4c60-8680-dad56a208e07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Função para auxiliar a limpeza dos dataframes\n",
    "def limpeza_cache(*args):\n",
    "    for df in args:\n",
    "        if hasattr(df, \"unpersist\"):\n",
    "            df.unpersist()\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e7b948f-7fc4-41b0-b15d-bff4c77b1d96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Dimensão Categoria\n",
    "- Aplicar SCD2\n",
    "- Aplicar SK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74b9ffe1-0637-401c-999c-7683acd23cbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+--------------------+--------------------+-------+-----+-----------+\n|CategoriaID|NomeCategoria|    DATA_ATUALIZACAO|             DataINI|DataFIM|ATIVO|CategoriaSK|\n+-----------+-------------+--------------------+--------------------+-------+-----+-----------+\n|          1|  Confections|2025-02-20 20:55:...|2025-02-20 20:55:...|   null| true|          1|\n|          6|      Seafood|2025-02-20 20:55:...|2025-02-20 20:55:...|   null| true|          2|\n|          3|      Cereals|2025-02-20 20:55:...|2025-02-20 20:55:...|   null| true|          3|\n|          5|    Beverages|2025-02-20 20:55:...|2025-02-20 20:55:...|   null| true|          4|\n|          9|      Poultry|2025-02-20 20:55:...|2025-02-20 20:55:...|   null| true|          5|\n+-----------+-------------+--------------------+--------------------+-------+-----+-----------+\nonly showing top 5 rows\n\nroot\n |-- CategoriaID: integer (nullable = true)\n |-- NomeCategoria: string (nullable = true)\n |-- DATA_ATUALIZACAO: timestamp (nullable = true)\n |-- DataINI: timestamp (nullable = true)\n |-- DataFIM: timestamp (nullable = true)\n |-- ATIVO: boolean (nullable = true)\n |-- CategoriaSK: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "sv_file = f'{sv_dim_path}/CATEGORIA'\n",
    "gd_file = f'{gd_dim_path}/CATEGORIA'\n",
    "\n",
    "# Carregamento de Categoria na Camada Silver\n",
    "df_categoria = spark.read.format(\"delta\").load(sv_file)\n",
    "\n",
    "# Procura de dados na camada Gold\n",
    "try:\n",
    "    df_categoria_gold = spark.read.format(\"delta\").load(gd_file)\n",
    "    ultimo_sk = df_categoria_gold.agg(max_(\"CategoriaSK\")).collect()[0][0]\n",
    "    if ultimo_sk is None:\n",
    "        ultimo_sk = 0\n",
    "except:\n",
    "    # Caso ainda não haja dados na Gold, cria-se o formato de tabela vazia\n",
    "    schema = df_categoria.schema \\\n",
    "                      .add(\"DataINI\", \"timestamp\") \\\n",
    "                      .add(\"DataFIM\", \"timestamp\") \\\n",
    "                      .add(\"ATIVO\", \"boolean\") \\\n",
    "                      .add(\"CategoriaSK\", \"long\")\n",
    "    df_categoria_gold = spark.createDataFrame([], schema)\n",
    "    ultimo_sk = 0\n",
    "\n",
    "# Ajustando a tipagem da coluna de SK nos Dataframes\n",
    "df_categoria = df_categoria.withColumn(\"CategoriaSK\", lit(None).cast(\"long\"))\n",
    "df_categoria_gold = df_categoria_gold.withColumn(\"CategoriaSK\", col(\"CategoriaSK\").cast(\"long\"))\n",
    "\n",
    "# Filtra registros ativos e inativos no caso de já existirem registros\n",
    "df_gold_ativos = df_categoria_gold.filter(col(\"Ativo\") == True)\n",
    "df_gold_inativos = df_categoria_gold.filter(col(\"Ativo\") == False)\n",
    "\n",
    "# Juntando registros ativos já existentes na gold com já existentes vindos da silver\n",
    "df_silver_gold = df_categoria.alias(\"silver\").join(df_categoria_gold.alias(\"gold\"), \"CategoriaID\", \"left\")\n",
    "\n",
    "# Checando se algum registro já existente na gold foi modificado\n",
    "df_updated = df_silver_gold.filter(col(\"silver.NomeCategoria\") != col(\"gold.NomeCategoria\"))\n",
    "\n",
    "# Marca os registros que foram modificados como INATIVO na gold (False)\n",
    "df_updated_inativos = df_updated.select(\n",
    "    col(\"gold.CategoriaID\"),\n",
    "    col(\"gold.NomeCategoria\"),\n",
    "    col(\"gold.DATA_ATUALIZACAO\"),\n",
    "    col(\"gold.DataINI\"),\n",
    "    current_timestamp().alias(\"DataFIM\"),\n",
    "    lit(False).alias(\"Ativo\"),\n",
    "    col(\"gold.CategoriaSK\")\n",
    ")\n",
    "\n",
    "# Inclusão das SKs nos registros novos e ATIVAÇÃO dos registros como vigentes (True)\n",
    "df_updated_novos = df_updated.select(\n",
    "    col(\"silver.CategoriaID\"),\n",
    "    col(\"silver.NomeCategoria\"),\n",
    "    col(\"silver.DATA_ATUALIZACAO\"),\n",
    "    col(\"silver.DATA_ATUALIZACAO\").alias(\"DataINI\"),\n",
    "    lit(None).cast(\"timestamp\").alias(\"DataFIM\"),\n",
    "    lit(True).alias(\"Ativo\"),\n",
    "    (monotonically_increasing_id() + ultimo_sk + 1).cast(\"long\").alias(\"CategoriaSK\")\n",
    ")\n",
    "\n",
    "# Contando quantos SKs já temos até o momento (juntando os ativos e os das modificações)\n",
    "total_sks = ultimo_sk + df_gold_ativos.count() + df_updated_novos.count()\n",
    "\n",
    "# Coletando os registros novos que não estavam em Gold ainda e inserindo SKs de acordo com a contagem\n",
    "df_novos_categoria = df_categoria.alias(\"silver\") \\\n",
    "    .join(df_gold_ativos.alias(\"gold\"), \"CategoriaID\", \"left_anti\") \\\n",
    "    .withColumn(\"DataINI\", col(\"silver.DATA_ATUALIZACAO\")) \\\n",
    "    .withColumn(\"DataFIM\", lit(None).cast(\"timestamp\")) \\\n",
    "    .withColumn(\"Ativo\", lit(True)) \\\n",
    "    .withColumn(\"CategoriaSK\", (monotonically_increasing_id() + total_sks + 1).cast(\"long\"))\n",
    "\n",
    "# Pegando a lista de CategoriaIDs dos dados modificados\n",
    "list_ids_updated = df_updated.select(\"CategoriaID\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# União dos registros atualizados (inativos e novos) na Gold e novos registros da Silver\n",
    "df_categoria_gold = df_gold_inativos \\\n",
    "    .unionByName(df_updated_inativos) \\\n",
    "    .unionByName(df_updated_novos) \\\n",
    "    .unionByName(df_novos_categoria) \\\n",
    "    .unionByName(df_gold_ativos.filter(~col(\"CategoriaID\").isin(list_ids_updated)))\n",
    "\n",
    "df_categoria_gold.show(5)\n",
    "df_categoria_gold.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f59e91d7-370d-4849-abef-f50a16e75701",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela salva em /mnt/desafio-dwe-25/lhdw/gold/dim/CATEGORIA:\n+-----------+-------------+--------------------+--------------------+-------+-----+-----------+\n|CategoriaID|NomeCategoria|    DATA_ATUALIZACAO|             DataINI|DataFIM|ATIVO|CategoriaSK|\n+-----------+-------------+--------------------+--------------------+-------+-----+-----------+\n|          1|  Confections|2025-02-20 20:55:...|2025-02-20 20:55:...|   null| true|          1|\n|          6|      Seafood|2025-02-20 20:55:...|2025-02-20 20:55:...|   null| true|          2|\n|          3|      Cereals|2025-02-20 20:55:...|2025-02-20 20:55:...|   null| true|          3|\n|          5|    Beverages|2025-02-20 20:55:...|2025-02-20 20:55:...|   null| true|          4|\n|          9|      Poultry|2025-02-20 20:55:...|2025-02-20 20:55:...|   null| true|          5|\n+-----------+-------------+--------------------+--------------------+-------+-----+-----------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "gold_path = f'{gd_dim_path}/CATEGORIA'\n",
    "\n",
    "df_categoria_gold.write.format(\"delta\").mode(\"overwrite\").save(gold_path)\n",
    "\n",
    "# Verificação dos resultados\n",
    "print(f'Tabela salva em {gold_path}:')\n",
    "spark.read.format(\"delta\").load(gold_path).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d44d7c81-50d2-4fcd-9118-c07d051731d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fazendo a limpeza dos Dataframes\n",
    "limpeza_cache(\n",
    "    df_categoria, df_categoria_gold, df_gold_ativos, \n",
    "    df_gold_inativos, df_novos_categoria, df_silver_gold, \n",
    "    df_updated, df_updated_inativos, df_updated_novos\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43c65659-c83c-4df9-83cc-72f8646ff0cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Dimensão Produto\n",
    "- Aplicar SCD2\n",
    "- Aplicar SK\n",
    "- Aplicar relação com Categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c00100ff-5000-455d-b979-940a4b80cc50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-------+------+--------------------+-----------+---------+------------+--------------------+--------------------+-------+-----+---------+-----------+\n|ProdutoID|         ProdutoNome|  Preco|Classe|        DataCadastro|Resistencia|EAlergico|ValidadeDias|    DATA_ATUALIZACAO|             DataINI|DataFIM|Ativo|ProdutoSK|CategoriaSK|\n+---------+--------------------+-------+------+--------------------+-----------+---------+------------+--------------------+--------------------+-------+-----+---------+-----------+\n|      148|Beer - Sleemans C...|28.5553|Medium|2018-04-19 00:16:...|    Durable|     True|        91.0|2025-02-20 20:55:...|2025-02-20 20:55:...|   null| true|        1|         10|\n|      243|Sun - Dried Tomatoes|45.1883|Medium|2017-11-02 21:24:...|       Weak|    False|       104.0|2025-02-20 20:55:...|2025-02-20 20:55:...|   null| true|        2|          2|\n|      392|Puree - Passion F...|98.8263|  High|2018-02-25 13:36:...|    Unknown|     True|        33.0|2025-02-20 20:55:...|2025-02-20 20:55:...|   null| true|        3|          4|\n|       31|Yeast Dry - Fermipan|73.9851|Medium|2017-04-17 23:33:...|    Durable|    False|         0.0|2025-02-20 20:55:...|2025-02-20 20:55:...|   null| true|        4|         11|\n|       85|Cheese - Parmesan...|86.8857|  High|2017-11-06 00:50:...|    Durable|  Unknown|         0.0|2025-02-20 20:55:...|2025-02-20 20:55:...|   null| true|        5|          8|\n+---------+--------------------+-------+------+--------------------+-----------+---------+------------+--------------------+--------------------+-------+-----+---------+-----------+\nonly showing top 5 rows\n\nroot\n |-- ProdutoID: integer (nullable = true)\n |-- ProdutoNome: string (nullable = true)\n |-- Preco: double (nullable = true)\n |-- Classe: string (nullable = true)\n |-- DataCadastro: string (nullable = true)\n |-- Resistencia: string (nullable = true)\n |-- EAlergico: string (nullable = true)\n |-- ValidadeDias: double (nullable = true)\n |-- DATA_ATUALIZACAO: timestamp (nullable = true)\n |-- DataINI: timestamp (nullable = true)\n |-- DataFIM: timestamp (nullable = true)\n |-- Ativo: boolean (nullable = true)\n |-- ProdutoSK: long (nullable = true)\n |-- CategoriaSK: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "sv_file = f'{sv_dim_path}/PRODUTO'\n",
    "gd_file = f'{gd_dim_path}/PRODUTO'\n",
    "gd_categoria = f'{gd_dim_path}/CATEGORIA'\n",
    "\n",
    "# Carregamento de Produto na Camada Silver\n",
    "df_produto = spark.read.format(\"delta\").load(sv_file)\n",
    "\n",
    "# Procura de dados na camada Gold\n",
    "try:\n",
    "    df_produto_gold = spark.read.format(\"delta\").load(gd_file)\n",
    "    ultimo_sk = df_produto_gold.agg(max_(\"ProdutoSK\")).collect()[0][0]\n",
    "    if ultimo_sk is None:\n",
    "        ultimo_sk = 0\n",
    "except:\n",
    "    # Caso ainda não haja dados na Gold, cria-se o formato de tabela vazia\n",
    "    schema = df_produto.schema \\\n",
    "                      .add(\"DataINI\", \"timestamp\") \\\n",
    "                      .add(\"DataFIM\", \"timestamp\") \\\n",
    "                      .add(\"Ativo\", \"boolean\") \\\n",
    "                      .add(\"ProdutoSK\", \"long\") \\\n",
    "                      .add(\"CategoriaSK\", \"long\")\n",
    "    df_produto_gold = spark.createDataFrame([], schema)\n",
    "    ultimo_sk = 0\n",
    "\n",
    "# Ajustando a tipagem da coluna de SK nos Dataframes\n",
    "df_produto = df_produto.withColumn(\"ProdutoSK\", lit(None).cast(\"long\"))\n",
    "df_produto_gold = df_produto_gold.withColumn(\"ProdutoSK\", col(\"ProdutoSK\").cast(\"long\"))\n",
    "\n",
    "# Trazendo SKs de Categoria na Gold\n",
    "df_categoria_gold = spark.read.format(\"delta\") \\\n",
    "    .load(gd_categoria).filter(col(\"Ativo\") == True) \\\n",
    "    .select(\"CategoriaID\", \"CategoriaSK\")\n",
    "\n",
    "# Fazendo a junção entre os produtos da Silver e as categorias da Gold\n",
    "df_produto = df_produto.join(df_categoria_gold, \"CategoriaID\", \"left\")\n",
    "\n",
    "# Certifica a existência da coluna\n",
    "if \"CategoriaID\" not in df_produto_gold.columns:\n",
    "    df_produto_gold.withColumn(\"CategoriaID\", lit(None).cast(dtype))\n",
    "    \n",
    "# Filtra registros ativos e inativos no caso de já existirem registros em Gold\n",
    "df_gold_ativos = df_produto_gold.filter(col(\"Ativo\") == True)\n",
    "df_gold_inativos = df_produto_gold.filter(col(\"Ativo\") == False)\n",
    "\n",
    "# Juntando registros ativos já existentes na gold com já existentes vindos da silver\n",
    "df_silver_gold = df_produto.alias(\"silver\").join(df_gold_ativos.alias(\"gold\"), \"ProdutoID\", \"left\")\n",
    "\n",
    "# Checando se algum registro já existente na Gold foi modificado\n",
    "df_modificados = df_silver_gold.filter(\n",
    "    (col(\"silver.ProdutoNome\") != col(\"gold.ProdutoNome\")) |\n",
    "    (col(\"silver.Preco\") != col(\"gold.Preco\")) |\n",
    "    (col(\"silver.CategoriaSK\") != col(\"gold.CategoriaSK\")) |\n",
    "    (col(\"Silver.Classe\") != col(\"gold.Classe\")) |\n",
    "    (col(\"silver.Resistencia\") != col(\"gold.Resistencia\")) |\n",
    "    (col(\"silver.EAlergico\") != col(\"gold.EAlergico\")) |\n",
    "    (col(\"silver.ValidadeDias\") != col(\"gold.ValidadeDias\"))\n",
    ")\n",
    "\n",
    "# Marca os registros antigos da Gold que foram modificados como INATIVO (False)\n",
    "df_modificados_inativos = df_modificados.select(\n",
    "    col(\"gold.ProdutoID\"),\n",
    "    col(\"gold.ProdutoNome\"),\n",
    "    col(\"gold.Preco\"),\n",
    "    col(\"gold.Classe\"),\n",
    "    col(\"gold.DataCadastro\"),\n",
    "    col(\"gold.Resistencia\"),\n",
    "    col(\"gold.EAlergico\"),\n",
    "    col(\"gold.ValidadeDias\"),\n",
    "    col(\"gold.DATA_ATUALIZACAO\"),\n",
    "    col(\"gold.DataINI\"),\n",
    "    col(\"gold.CategoriaSK\"),\n",
    "    current_timestamp().alias(\"DataFIM\"),\n",
    "    lit(False).alias(\"Ativo\"),\n",
    "    col(\"gold.ProdutoSK\"),\n",
    "    col(\"gold.CategoriaID\")\n",
    ")\n",
    "\n",
    "# Inclusão das SKs nos registros novos que vem da Silver e ATIVAÇÃO dos registros como vigentes (True)\n",
    "df_modificados_novos = df_modificados.select(\n",
    "    col(\"silver.ProdutoID\"),\n",
    "    col(\"silver.ProdutoNome\"),\n",
    "    col(\"silver.Preco\"),\n",
    "    col(\"silver.Classe\"),\n",
    "    col(\"silver.DataCadastro\"),\n",
    "    col(\"silver.Resistencia\"),\n",
    "    col(\"silver.EAlergico\"),\n",
    "    col(\"silver.ValidadeDias\"),\n",
    "    col(\"silver.DATA_ATUALIZACAO\"),\n",
    "    col(\"silver.DATA_ATUALIZACAO\").alias(\"DataINI\"),\n",
    "    col(\"silver.CategoriaSK\"),\n",
    "    lit(None).cast(\"timestamp\").alias(\"DataFIM\"),\n",
    "    lit(True).alias(\"Ativo\"),\n",
    "    (monotonically_increasing_id() + ultimo_sk + 1).cast(\"long\").alias(\"ProdutoSK\"),\n",
    "    col(\"silver.CategoriaID\")\n",
    ")\n",
    "\n",
    "# Contando quantos SKs já temos até o momento (juntando os ativos e os das modificações)\n",
    "total_sks = ultimo_sk + df_gold_ativos.count() + df_modificados_novos.count()\n",
    "\n",
    "# Coletando os registros novos que não estavam em Gold ainda e inserindo SKs de acordo com a contagem\n",
    "df_novos_produtos = df_produto.alias(\"silver\") \\\n",
    "    .join(df_gold_ativos.alias(\"gold\"), \"ProdutoID\", \"left_anti\") \\\n",
    "    .withColumn(\"DataINI\", col(\"silver.DATA_ATUALIZACAO\")) \\\n",
    "    .withColumn(\"DataFIM\", lit(None).cast(\"timestamp\")) \\\n",
    "    .withColumn(\"Ativo\", lit(True)) \\\n",
    "    .withColumn(\"ProdutoSK\", (monotonically_increasing_id() + total_sks + 1).cast(\"long\"))\n",
    "\n",
    "# Pegando a lista de ProdutoIDs dos dados modificados\n",
    "list_ids_modificados = df_modificados.select(\"ProdutoID\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# União dos registros atualizados (inativos e novos) na Gold e novos registros da Silver\n",
    "df_produto_gold = df_gold_inativos \\\n",
    "    .unionByName(df_modificados_inativos) \\\n",
    "    .unionByName(df_modificados_novos) \\\n",
    "    .unionByName(df_novos_produtos) \\\n",
    "    .unionByName(df_gold_ativos.filter(~col(\"ProdutoID\").isin(list_ids_modificados)))\n",
    "\n",
    "# Dropando a coluna CategoriaID da tabela final\n",
    "df_produto_gold = df_produto_gold.drop(\"CategoriaID\")\n",
    "\n",
    "# Verificando schema antes de salvar\n",
    "df_produto_gold.show(5)\n",
    "df_produto_gold.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47318843-f083-44cf-81cb-547026d39798",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela salva em /mnt/desafio-dwe-25/lhdw/gold/dim/PRODUTO:\n+---------+--------------------+-------+------+--------------------+-----------+---------+------------+--------------------+--------------------+-------+-----+---------+-----------+\n|ProdutoID|         ProdutoNome|  Preco|Classe|        DataCadastro|Resistencia|EAlergico|ValidadeDias|    DATA_ATUALIZACAO|             DataINI|DataFIM|Ativo|ProdutoSK|CategoriaSK|\n+---------+--------------------+-------+------+--------------------+-----------+---------+------------+--------------------+--------------------+-------+-----+---------+-----------+\n|        1| Flour - Whole Wheat|74.2988|Medium|2018-02-16 08:21:...|    Durable|  Unknown|         0.0|2025-02-20 20:55:...|2025-02-20 20:55:...|   null| true|        1|          3|\n|        2|Cookie Chocolate ...|91.2329|Medium|2017-02-12 11:39:...|    Unknown|  Unknown|         0.0|2025-02-20 20:55:...|2025-02-20 20:55:...|   null| true|        2|          3|\n|        3|  Onions - Cippolini| 9.1379|Medium|2018-03-15 08:11:...|       Weak|    False|       111.0|2025-02-20 20:55:...|2025-02-20 20:55:...|   null| true|        3|          5|\n|        4|Sauce - Gravy, Au...|54.3055|Medium|2017-07-16 00:46:...|    Durable|  Unknown|         0.0|2025-02-20 20:55:...|2025-02-20 20:55:...|   null| true|        4|          5|\n|        5|Artichokes - Jeru...|65.4771|   Low|2017-08-16 14:13:...|    Durable|     True|        27.0|2025-02-20 20:55:...|2025-02-20 20:55:...|   null| true|        5|         11|\n+---------+--------------------+-------+------+--------------------+-----------+---------+------------+--------------------+--------------------+-------+-----+---------+-----------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "gold_path = f'{gd_dim_path}/PRODUTO'\n",
    "\n",
    "# Salvando os arquivos na Gold\n",
    "df_produto_gold.write.format(\"delta\").mode(\"overwrite\").save(gold_path)\n",
    "\n",
    "# Verificação dos resultados\n",
    "print(f'Tabela salva em {gold_path}:')\n",
    "spark.read.format(\"delta\").load(gold_path).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bad351fe-0ca2-45fd-a200-479fa94d3b6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Limpando cache do cluster\n",
    "limpeza_cache(\n",
    "    df_categoria_gold, df_gold_ativos, df_gold_inativos,\n",
    "    df_modificados, df_modificados_inativos, df_modificados_novos,\n",
    "    df_novos_produtos, df_produto, df_produto_gold, df_silver_gold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24196d55-3f06-4ff9-b92c-623bbd2713cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Dimensão - Vendedores\n",
    "- Aplicar SCD2\n",
    "- Aplicar SK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52cd80f4-a6b2-498e-a249-8ef057c8b0be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+--------------+------+--------+------------+--------------------+--------------------+-------+-----+----------+\n|VendedorID|     NomeVendedor|DataNascimento|Genero|CidadeID|DataAdmissao|    DATA_ATUALIZACAO|             DataINI|DataFIM|ATIVO|VendedorSK|\n+----------+-----------------+--------------+------+--------+------------+--------------------+--------------------+-------+-----+----------+\n|        12|   Lindsay M Chen|    1951-09-03|     F|      58|  2011-11-03|2025-02-21 18:43:...|2025-02-21 18:43:...|   null| true|         1|\n|        22|Tonia O Mc Millan|    1952-03-02|     F|      53|  2015-11-25|2025-02-21 18:43:...|2025-02-21 18:43:...|   null| true|         2|\n|         1|  Nicole T Fuller|    1981-03-07|     F|      80|  2011-06-20|2025-02-21 18:43:...|2025-02-21 18:43:...|   null| true|         3|\n|        13|   Katina Y Marks|    1963-04-18|     M|      68|  2011-12-12|2025-02-21 18:43:...|2025-02-21 18:43:...|   null| true|         4|\n|         6|  Holly E Collins|    1987-01-13|     M|      65|  2013-06-22|2025-02-21 18:43:...|2025-02-21 18:43:...|   null| true|         5|\n+----------+-----------------+--------------+------+--------+------------+--------------------+--------------------+-------+-----+----------+\nonly showing top 5 rows\n\nroot\n |-- VendedorID: integer (nullable = true)\n |-- NomeVendedor: string (nullable = true)\n |-- DataNascimento: date (nullable = true)\n |-- Genero: string (nullable = true)\n |-- CidadeID: integer (nullable = true)\n |-- DataAdmissao: date (nullable = true)\n |-- DATA_ATUALIZACAO: timestamp (nullable = true)\n |-- DataINI: timestamp (nullable = true)\n |-- DataFIM: timestamp (nullable = true)\n |-- ATIVO: boolean (nullable = true)\n |-- VendedorSK: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "sv_file = f'{sv_dim_path}/VENDEDOR'\n",
    "gd_file = f'{gd_dim_path}/VENDEDOR'\n",
    "\n",
    "# Carregamento de Vendedor na Camada Silver\n",
    "df_vendedor = spark.read.format(\"delta\").load(sv_file)\n",
    "\n",
    "# Procura de dados existentes na camada Gold\n",
    "try:\n",
    "    df_vendedor_gold = spark.read.format(\"delta\").load(gd_file)\n",
    "    ultimo_sk = df_vendedor_gold.agg(max_(\"VendedorSK\")).collect()[0][0]\n",
    "    if ultimo_sk is None:\n",
    "        ultimo_sk = 0\n",
    "except:\n",
    "    # Caso ainda não haja dados na Gold, cria-se o formato de tabela vazia\n",
    "    schema = df_vendedor.schema \\\n",
    "                      .add(\"DataINI\", \"timestamp\") \\\n",
    "                      .add(\"DataFIM\", \"timestamp\") \\\n",
    "                      .add(\"Ativo\", \"boolean\") \\\n",
    "                      .add(\"VendedorSK\", \"long\")\n",
    "    df_vendedor_gold = spark.createDataFrame([], schema)\n",
    "    ultimo_sk = 0\n",
    "\n",
    "\n",
    "# Ajuste da tipagem da coluna de SK nos Dataframes\n",
    "df_vendedor = df_vendedor.withColumn(\"VendedorSK\", lit(None).cast(\"long\"))\n",
    "df_vendedor_gold = df_vendedor_gold.withColumn(\"VendedorSK\", col(\"VendedorSK\").cast(\"long\"))\n",
    "\n",
    "# Filtra registros ativos e inativos no caso de já existirem registros na Gold\n",
    "df_gold_ativos = df_vendedor_gold.filter(col(\"Ativo\") == True)\n",
    "df_gold_inativos = df_vendedor_gold.filter(col(\"Ativo\") == False)\n",
    "\n",
    "# Juntando registros ativos já existentes na Gold os vindos da Silver para achar mudanças\n",
    "df_silver_gold = df_vendedor.alias(\"silver\").join(df_vendedor_gold.alias(\"gold\"), \"VendedorID\", \"left\")\n",
    "\n",
    "# Checando se algum registro existente na gold foi modificado por comparação Silver - Gold\n",
    "df_modificados = df_silver_gold.filter(\n",
    "    (col(\"silver.NomeVendedor\") != col(\"gold.NomeVendedor\")) |\n",
    "    (col(\"silver.DataNascimento\") != col(\"gold.DataNascimento\")) |\n",
    "    (col(\"silver.Genero\") != col(\"gold.Genero\")) |\n",
    "    (col(\"silver.CidadeID\") != col(\"gold.CidadeID\")) |\n",
    "    (col(\"silver.DataAdmissao\") != col(\"gold.DataAdmissao\"))\n",
    ")\n",
    "\n",
    "# Marca os registros que foram modificados como INATIVO na Gold (False)\n",
    "df_modificados_inativos = df_modificados.select(\n",
    "    col(\"gold.VendedorID\"),\n",
    "    col(\"gold.NomeVendedor\"),\n",
    "    col(\"gold.DataNascimento\"),\n",
    "    col(\"gold.Genero\"),\n",
    "    col(\"gold.CidadeID\"),\n",
    "    col(\"gold.DataAdmissao\"),\n",
    "    col(\"gold.DATA_ATUALIZACAO\"),\n",
    "    col(\"gold.DataINI\"),\n",
    "    current_timestamp().alias(\"DataFIM\"),\n",
    "    lit(False).alias(\"Ativo\"),\n",
    "    col(\"gold.VendedorSK\")\n",
    ")\n",
    "\n",
    "# Inclusão das SKs nos registros novos e ATIVAÇÃO dos registros como vigentes (True)\n",
    "df_modificados_novos = df_modificados.select(\n",
    "    col(\"silver.VendedorID\"),\n",
    "    col(\"silver.NomeVendedor\"),\n",
    "    col(\"silver.DataNascimento\"),\n",
    "    col(\"silver.Genero\"),\n",
    "    col(\"silver.CidadeID\"),\n",
    "    col(\"silver.DataAdmissao\"),\n",
    "    col(\"silver.DATA_ATUALIZACAO\"),\n",
    "    col(\"silver.DATA_ATUALIZACAO\").alias(\"DataINI\"),\n",
    "    lit(None).cast(\"timestamp\").alias(\"DataFIM\"),\n",
    "    lit(True).alias(\"Ativo\"),\n",
    "    (monotonically_increasing_id() + ultimo_sk + 1).cast(\"long\").alias(\"VendedorSK\")\n",
    ")\n",
    "\n",
    "\n",
    "# Contando quantos SKs já temos até o momento (juntando os ativos e os das modificações)\n",
    "total_sks = ultimo_sk + df_gold_ativos.count() + df_modificados_novos.count()\n",
    "\n",
    "# Coletando os registros novos que não estavam em Gold ainda e inserindo data e SKs de acordo com a contagem\n",
    "df_novos_vendedores = df_vendedor.alias(\"silver\") \\\n",
    "    .join(df_gold_ativos.alias(\"gold\"), \"VendedorID\", \"left_anti\") \\\n",
    "    .withColumn(\"DataINI\", col(\"silver.DATA_ATUALIZACAO\")) \\\n",
    "    .withColumn(\"DataFIM\", lit(None).cast(\"timestamp\")) \\\n",
    "    .withColumn(\"Ativo\", lit(True)) \\\n",
    "    .withColumn(\"VendedorSK\", (monotonically_increasing_id() + total_sks + 1).cast(\"long\"))\n",
    "\n",
    "\n",
    "# Pegando a lista de VendedorIDs dos dados modificados\n",
    "vendedores_modificados = df_modificados.select(\"VendedorID\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# União dos registros atualizados (inativos e novos ativos) da Gold e novos registros vindos da Silver\n",
    "df_vendedor_gold = df_gold_inativos \\\n",
    "    .unionByName(df_modificados_inativos) \\\n",
    "    .unionByName(df_modificados_novos) \\\n",
    "    .unionByName(df_novos_vendedores) \\\n",
    "    .unionByName(df_gold_ativos.filter(~col(\"VendedorID\").isin(vendedores_modificados)))\n",
    "\n",
    "df_vendedor_gold.show(5)\n",
    "df_vendedor_gold.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f457a291-2aa1-4c17-8db4-8d4d997e9d4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela salva em /mnt/desafio-dwe-25/lhdw/gold/dim/VENDEDOR:\n+----------+-----------------+--------------+------+--------+------------+--------------------+--------------------+-------+-----+----------+\n|VendedorID|     NomeVendedor|DataNascimento|Genero|CidadeID|DataAdmissao|    DATA_ATUALIZACAO|             DataINI|DataFIM|ATIVO|VendedorSK|\n+----------+-----------------+--------------+------+--------+------------+--------------------+--------------------+-------+-----+----------+\n|        12|   Lindsay M Chen|    1951-09-03|     F|      58|  2011-11-03|2025-02-21 18:43:...|2025-02-21 18:43:...|   null| true|         1|\n|        22|Tonia O Mc Millan|    1952-03-02|     F|      53|  2015-11-25|2025-02-21 18:43:...|2025-02-21 18:43:...|   null| true|         2|\n|         1|  Nicole T Fuller|    1981-03-07|     F|      80|  2011-06-20|2025-02-21 18:43:...|2025-02-21 18:43:...|   null| true|         3|\n|        13|   Katina Y Marks|    1963-04-18|     M|      68|  2011-12-12|2025-02-21 18:43:...|2025-02-21 18:43:...|   null| true|         4|\n|         6|  Holly E Collins|    1987-01-13|     M|      65|  2013-06-22|2025-02-21 18:43:...|2025-02-21 18:43:...|   null| true|         5|\n+----------+-----------------+--------------+------+--------+------------+--------------------+--------------------+-------+-----+----------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "gold_path = f'{gd_dim_path}/VENDEDOR'\n",
    "\n",
    "df_vendedor_gold.write.format(\"delta\").mode(\"overwrite\").save(gold_path)\n",
    "\n",
    "# Verificação dos resultados\n",
    "print(f'Tabela salva em {gold_path}:')\n",
    "spark.read.format(\"delta\").load(gold_path).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f6fed32-7531-4da0-a12e-f3514fab1e54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Limpando o cache\n",
    "limpeza_cache(\n",
    "    df_gold_ativos, df_gold_inativos, df_modificados,\n",
    "    df_modificados_inativos, df_modificados_novos, df_novos_vendedores,\n",
    "    df_silver_gold, df_vendedor, df_vendedor_gold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5e63666-18fb-4e70-a82e-5af2cb41149a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Dimensão - País\n",
    "- Aplicar SCD2\n",
    "- Aplicar SK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "063a14ff-cba5-4a43-acf7-5ca6a1914715",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------+--------------------+--------------------+-------+-----+------+\n|PaisID|PaisNome|SiglaPais|    DATA_ATUALIZACAO|             DataINI|DataFIM|Ativo|PaisSK|\n+------+--------+---------+--------------------+--------------------+-------+-----+------+\n|   148|    Mali|       BF|2025-02-21 18:43:...|2025-02-21 18:43:...|   null| true|     1|\n|    31|   Congo|       TR|2025-02-21 18:43:...|2025-02-21 18:43:...|   null| true|     2|\n|    85|   Yemen|       NO|2025-02-21 18:43:...|2025-02-21 18:43:...|   null| true|     3|\n|   137|    Fiji|       MQ|2025-02-21 18:43:...|2025-02-21 18:43:...|   null| true|     4|\n|    65| Lebanon|       LA|2025-02-21 18:43:...|2025-02-21 18:43:...|   null| true|     5|\n+------+--------+---------+--------------------+--------------------+-------+-----+------+\nonly showing top 5 rows\n\nroot\n |-- PaisID: integer (nullable = true)\n |-- PaisNome: string (nullable = true)\n |-- SiglaPais: string (nullable = true)\n |-- DATA_ATUALIZACAO: timestamp (nullable = true)\n |-- DataINI: timestamp (nullable = true)\n |-- DataFIM: timestamp (nullable = true)\n |-- Ativo: boolean (nullable = true)\n |-- PaisSK: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "sv_file = f'{sv_dim_path}/PAIS'\n",
    "gd_file = f'{gd_dim_path}/PAIS'\n",
    "\n",
    "# Carregamento de País na Camada Silver\n",
    "df_pais = spark.read.format(\"delta\").load(sv_file)\n",
    "\n",
    "# Procura de dados existentes na camada Gold\n",
    "try:\n",
    "    df_pais_gold = spark.read.format(\"delta\").load(gd_file)\n",
    "    ultimo_sk = df_pais_gold.agg(max_(\"PaisSK\")).collect()[0][0]\n",
    "    if ultimo_sk is None:\n",
    "        ultimo_sk = 0\n",
    "except:\n",
    "    # Caso ainda não haja dados na Gold, cria-se o formato de tabela vazia\n",
    "    schema = df_pais.schema \\\n",
    "                      .add(\"DataINI\", \"timestamp\") \\\n",
    "                      .add(\"DataFIM\", \"timestamp\") \\\n",
    "                      .add(\"Ativo\", \"boolean\") \\\n",
    "                      .add(\"PaisSK\", \"long\")\n",
    "    df_pais_gold = spark.createDataFrame([], schema)\n",
    "    ultimo_sk = 0\n",
    "\n",
    "\n",
    "# Ajuste da tipagem da coluna de SK nos Dataframes\n",
    "df_pais = df_pais.withColumn(\"PaisSK\", lit(None).cast(\"long\"))\n",
    "df_pais_gold = df_pais_gold.withColumn(\"PaisSK\", col(\"PaisSK\").cast(\"long\"))\n",
    "\n",
    "# Filtra registros ativos e inativos no caso de já existirem registros na Gold\n",
    "df_gold_ativos = df_pais_gold.filter(col(\"Ativo\") == True)\n",
    "df_gold_inativos = df_pais_gold.filter(col(\"Ativo\") == False)\n",
    "\n",
    "# Juntando registros ativos já existentes na Gold os vindos da Silver para achar mudanças\n",
    "df_silver_gold = df_pais.alias(\"silver\").join(df_pais_gold.alias(\"gold\"), \"PaisID\", \"left\")\n",
    "\n",
    "# Checando se algum registro existente na gold foi modificado por comparação Silver - Gold\n",
    "df_modificados = df_silver_gold.filter(\n",
    "    (col(\"silver.PaisNome\") != col(\"gold.PaisNome\")) |\n",
    "    (col(\"silver.SiglaPais\") != col(\"gold.SiglaPais\")) \n",
    ")\n",
    "\n",
    "# Marca os registros que foram modificados como INATIVO na Gold (False)\n",
    "df_modificados_inativos = df_modificados.select(\n",
    "    col(\"gold.PaisID\"),\n",
    "    col(\"gold.PaisNome\"),\n",
    "    col(\"gold.SiglaPais\"),\n",
    "    col(\"gold.DATA_ATUALIZACAO\"),\n",
    "    col(\"gold.DataINI\"),\n",
    "    current_timestamp().alias(\"DataFIM\"),\n",
    "    lit(False).alias(\"Ativo\"),\n",
    "    col(\"gold.PaisSK\")\n",
    ")\n",
    "\n",
    "# Inclusão das SKs nos registros novos e ATIVAÇÃO dos registros como vigentes (True)\n",
    "df_modificados_novos = df_modificados.select(\n",
    "    col(\"silver.PaisID\"),\n",
    "    col(\"silver.PaisNome\"),\n",
    "    col(\"silver.SiglaPais\"),\n",
    "    col(\"silver.DATA_ATUALIZACAO\"),\n",
    "    col(\"silver.DATA_ATUALIZACAO\").alias(\"DataINI\"),\n",
    "    lit(None).cast(\"timestamp\").alias(\"DataFIM\"),\n",
    "    lit(True).alias(\"Ativo\"),\n",
    "    (monotonically_increasing_id() + ultimo_sk + 1).cast(\"long\").alias(\"PaisSK\")\n",
    ")\n",
    "\n",
    "\n",
    "# Contando quantos SKs já temos até o momento (juntando os ativos e os das modificações)\n",
    "total_sks = ultimo_sk + df_gold_ativos.count() + df_modificados_novos.count()\n",
    "\n",
    "# Coletando os registros novos que não estavam em Gold ainda e inserindo data e SKs de acordo com a contagem\n",
    "df_novos_paises = df_pais.alias(\"silver\") \\\n",
    "    .join(df_gold_ativos.alias(\"gold\"), \"PaisID\", \"left_anti\") \\\n",
    "    .withColumn(\"DataINI\", col(\"silver.DATA_ATUALIZACAO\")) \\\n",
    "    .withColumn(\"DataFIM\", lit(None).cast(\"timestamp\")) \\\n",
    "    .withColumn(\"Ativo\", lit(True)) \\\n",
    "    .withColumn(\"PaisSK\", (monotonically_increasing_id() + total_sks + 1).cast(\"long\"))\n",
    "\n",
    "\n",
    "# Pegando a lista de PaisIDs dos dados modificados\n",
    "paises_modificados = df_modificados.select(\"PaisID\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# União dos registros atualizados (inativos e novos ativos) da Gold e novos registros vindos da Silver\n",
    "df_pais_gold = df_gold_inativos \\\n",
    "    .unionByName(df_modificados_inativos) \\\n",
    "    .unionByName(df_modificados_novos) \\\n",
    "    .unionByName(df_novos_paises) \\\n",
    "    .unionByName(df_gold_ativos.filter(~col(\"PaisID\").isin(paises_modificados)))\n",
    "\n",
    "df_pais_gold.show(5)\n",
    "df_pais_gold.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17a85a7c-2146-4b8e-87c3-f37b5f961207",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela salva em /mnt/desafio-dwe-25/lhdw/gold/dim/PAIS:\n+------+--------+---------+--------------------+--------------------+-------+-----+------+\n|PaisID|PaisNome|SiglaPais|    DATA_ATUALIZACAO|             DataINI|DataFIM|Ativo|PaisSK|\n+------+--------+---------+--------------------+--------------------+-------+-----+------+\n|   148|    Mali|       BF|2025-02-21 18:43:...|2025-02-21 18:43:...|   null| true|     1|\n|    31|   Congo|       TR|2025-02-21 18:43:...|2025-02-21 18:43:...|   null| true|     2|\n|    85|   Yemen|       NO|2025-02-21 18:43:...|2025-02-21 18:43:...|   null| true|     3|\n|   137|    Fiji|       MQ|2025-02-21 18:43:...|2025-02-21 18:43:...|   null| true|     4|\n|    65| Lebanon|       LA|2025-02-21 18:43:...|2025-02-21 18:43:...|   null| true|     5|\n+------+--------+---------+--------------------+--------------------+-------+-----+------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "gold_path = f'{gd_dim_path}/PAIS'\n",
    "\n",
    "df_pais_gold.write.format(\"delta\").mode(\"overwrite\").save(gold_path)\n",
    "\n",
    "# Verificação dos resultados\n",
    "print(f'Tabela salva em {gold_path}:')\n",
    "spark.read.format(\"delta\").load(gold_path).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88f731f1-1828-40eb-9082-32b6aa7bc9ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Dimensão - Cidade\n",
    "- Aplicar SCD2\n",
    "- Aplicar SK\n",
    "- Aplicar relação com País"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "575120b3-f4d0-4c29-ae81-36c1dc8a5a96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+-----+--------------------+--------------------+-------+-----+--------+------+\n|CidadeID|    NomeCidade|  Cep|    DATA_ATUALIZACAO|             DataINI|DataFIM|Ativo|CidadeSK|PaisSK|\n+--------+--------------+-----+--------------------+--------------------+-------+-----+--------+------+\n|       1|        Dayton|80563|2025-02-21 18:45:...|2025-02-21 18:45:...|   null| true|       1|   146|\n|       2|       Buffalo|17420|2025-02-21 18:45:...|2025-02-21 18:45:...|   null| true|       2|   146|\n|       3|       Chicago|44751|2025-02-21 18:45:...|2025-02-21 18:45:...|   null| true|       3|   146|\n|       4|       Fremont|20641|2025-02-21 18:45:...|2025-02-21 18:45:...|   null| true|       4|   146|\n|       5|Virginia Beach|62389|2025-02-21 18:45:...|2025-02-21 18:45:...|   null| true|       5|   146|\n+--------+--------------+-----+--------------------+--------------------+-------+-----+--------+------+\nonly showing top 5 rows\n\nroot\n |-- CidadeID: integer (nullable = true)\n |-- NomeCidade: string (nullable = true)\n |-- Cep: string (nullable = true)\n |-- DATA_ATUALIZACAO: timestamp (nullable = true)\n |-- DataINI: timestamp (nullable = true)\n |-- DataFIM: timestamp (nullable = true)\n |-- Ativo: boolean (nullable = true)\n |-- CidadeSK: long (nullable = true)\n |-- PaisSK: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "sv_file = f'{sv_dim_path}/CIDADE'\n",
    "gd_file = f'{gd_dim_path}/CIDADE'\n",
    "gd_pais = f'{gd_dim_path}/PAIS'\n",
    "\n",
    "# Carregamento de Cidade na Camada Silver\n",
    "df_cidade = spark.read.format(\"delta\").load(sv_file)\n",
    "\n",
    "# Procura de dados na camada Gold\n",
    "try:\n",
    "    df_cidade_gold = spark.read.format(\"delta\").load(gd_file)\n",
    "    ultimo_sk = df_cidade_gold.agg(max_(\"CidadeSK\")).collect()[0][0]\n",
    "    if ultimo_sk is None:\n",
    "        ultimo_sk = 0\n",
    "except:\n",
    "    # Caso ainda não haja dados na Gold, cria-se o formato de tabela vazia\n",
    "    # já inserindo a SK de Cidade e a SK estrangeira de País\n",
    "    schema = df_cidade.schema \\\n",
    "                      .add(\"DataINI\", \"timestamp\") \\\n",
    "                      .add(\"DataFIM\", \"timestamp\") \\\n",
    "                      .add(\"Ativo\", \"boolean\") \\\n",
    "                      .add(\"CidadeSK\", \"long\") \\\n",
    "                      .add(\"PaisSK\", \"long\")\n",
    "    df_cidade_gold = spark.createDataFrame([], schema)\n",
    "    ultimo_sk = 0\n",
    "\n",
    "\n",
    "# Ajustando a tipagem da coluna de SK nos Dataframes\n",
    "df_cidade = df_cidade.withColumn(\"CidadeSK\", lit(None).cast(\"long\"))\n",
    "df_cidade_gold = df_cidade_gold.withColumn(\"CidadeSK\", col(\"CidadeSK\").cast(\"long\"))\n",
    "\n",
    "# Trazendo SKs e IDs de País da Gold\n",
    "df_pais_gold = spark.read.format(\"delta\") \\\n",
    "    .load(gd_pais).filter(col(\"Ativo\") == True) \\\n",
    "    .select(\"PaisID\", \"PaisSK\")\n",
    "\n",
    "# Fazendo a junção entre as cidades da Silver e os países da Gold\n",
    "df_cidade = df_cidade.join(df_pais_gold, \"PaisID\", \"left\")\n",
    "\n",
    "# Certifica a existência da coluna PaisID nos dados da Gold\n",
    "if \"PaisID\" not in df_cidade_gold.columns:\n",
    "    df_cidade_gold.withColumn(\"PaisID\", lit(None).cast(dtype))\n",
    "    \n",
    "# Filtra registros ativos e inativos no caso de já existirem registros em Gold\n",
    "df_gold_ativos = df_cidade_gold.filter(col(\"Ativo\") == True)\n",
    "df_gold_inativos = df_cidade_gold.filter(col(\"Ativo\") == False)\n",
    "\n",
    "# Juntando registros ativos já existentes na Gold com os vindos da Silver para achar mudanças\n",
    "df_silver_gold = df_cidade.alias(\"silver\").join(df_gold_ativos.alias(\"gold\"), \"CidadeID\", \"left\")\n",
    "\n",
    "# Checando se algum registro existente na gold foi modificado por comparação Silver - Gold\n",
    "df_modificados = df_silver_gold.filter(\n",
    "    (col(\"silver.NomeCidade\") != col(\"gold.NomeCidade\")) |\n",
    "    (col(\"silver.Cep\") != col(\"gold.Cep\")) |\n",
    "    (col(\"silver.PaisSK\") != col(\"gold.PaisSK\"))\n",
    ")\n",
    "\n",
    "# Marca os registros antigos da Gold que foram modificados como INATIVO (False)\n",
    "df_modificados_inativos = df_modificados.select(\n",
    "    col(\"gold.CidadeID\"),\n",
    "    col(\"gold.NomeCidade\"),\n",
    "    col(\"gold.Cep\"),\n",
    "    col(\"gold.DATA_ATUALIZACAO\"),\n",
    "    col(\"gold.DataINI\"),\n",
    "    col(\"gold.PaisSK\"),\n",
    "    current_timestamp().alias(\"DataFIM\"),\n",
    "    lit(False).alias(\"Ativo\"),\n",
    "    col(\"gold.CidadeSK\"),\n",
    "    col(\"gold.PaisID\")\n",
    ")\n",
    "\n",
    "# Inclusão das SKs nos registros novos que vem da Silver e ATIVAÇÃO dos registros como vigentes (True)\n",
    "df_modificados_novos = df_modificados.select(\n",
    "    col(\"silver.CidadeID\"),\n",
    "    col(\"silver.NomeCidade\"),\n",
    "    col(\"silver.Cep\"),\n",
    "    col(\"silver.DATA_ATUALIZACAO\"),\n",
    "    col(\"silver.DATA_ATUALIZACAO\").alias(\"DataINI\"),\n",
    "    col(\"silver.PaisSK\"),\n",
    "    lit(None).cast(\"timestamp\").alias(\"DataFIM\"),\n",
    "    lit(True).alias(\"Ativo\"),\n",
    "    (monotonically_increasing_id() + ultimo_sk + 1).cast(\"long\").alias(\"CidadeSK\"),\n",
    "    col(\"silver.PaisID\")\n",
    ")\n",
    "\n",
    "# Contando quantos SKs já temos até o momento (juntando os ativos e os das modificações)\n",
    "total_sks = ultimo_sk + df_gold_ativos.count() + df_modificados_novos.count()\n",
    "\n",
    "# Coletando os registros novos que não estavam em Gold ainda e inserindo data e SKs de acordo com a contagem\n",
    "df_novas_cidades = df_cidade.alias(\"silver\") \\\n",
    "    .join(df_gold_ativos.alias(\"gold\"), \"CidadeID\", \"left_anti\") \\\n",
    "    .withColumn(\"DataINI\", col(\"silver.DATA_ATUALIZACAO\")) \\\n",
    "    .withColumn(\"DataFIM\", lit(None).cast(\"timestamp\")) \\\n",
    "    .withColumn(\"Ativo\", lit(True)) \\\n",
    "    .withColumn(\"CidadeSK\", (monotonically_increasing_id() + total_sks + 1).cast(\"long\"))\n",
    "\n",
    "# Pegando a lista de CidadeIDs dos dados modificados\n",
    "ids_modificados = df_modificados.select(\"CidadeID\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# União dos registros atualizados (inativos e novos ativos) da Gold e novos registros vindos da Silver\n",
    "df_cidade_gold = df_gold_inativos \\\n",
    "    .unionByName(df_modificados_inativos) \\\n",
    "    .unionByName(df_modificados_novos) \\\n",
    "    .unionByName(df_novas_cidades) \\\n",
    "    .unionByName(df_gold_ativos.filter(~col(\"CidadeID\").isin(ids_modificados)))\n",
    "\n",
    "# Dropando a coluna PaisID da tabela final\n",
    "df_cidade_gold = df_cidade_gold.drop(\"PaisID\")\n",
    "\n",
    "# Verificando schema antes de salvar\n",
    "df_cidade_gold.show(5)\n",
    "df_cidade_gold.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2310b55-97c7-4b08-bbf7-802b297d7e49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela salva em /mnt/desafio-dwe-25/lhdw/gold/dim/CIDADE:\n+--------+--------------+-----+--------------------+--------------------+-------+-----+--------+------+\n|CidadeID|    NomeCidade|  Cep|    DATA_ATUALIZACAO|             DataINI|DataFIM|Ativo|CidadeSK|PaisSK|\n+--------+--------------+-----+--------------------+--------------------+-------+-----+--------+------+\n|      31|       Wichita|93028|2025-02-21 18:45:...|2025-02-21 18:45:...|   null| true|       1|   146|\n|      85|St. Petersburg|88713|2025-02-21 18:45:...|2025-02-21 18:45:...|   null| true|       2|   146|\n|      65|     Baltimore|89197|2025-02-21 18:45:...|2025-02-21 18:45:...|   null| true|       3|   146|\n|      53|     Las Vegas|90989|2025-02-21 18:45:...|2025-02-21 18:45:...|   null| true|       4|   146|\n|      78|     San Diego|83701|2025-02-21 18:45:...|2025-02-21 18:45:...|   null| true|       5|   146|\n+--------+--------------+-----+--------------------+--------------------+-------+-----+--------+------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "gold_path = f'{gd_dim_path}/CIDADE'\n",
    "\n",
    "# Salvando os arquivos na Gold\n",
    "df_cidade_gold.write.format(\"delta\").mode(\"overwrite\").save(gold_path)\n",
    "\n",
    "# Verificação dos resultados\n",
    "print(f'Tabela salva em {gold_path}:')\n",
    "spark.read.format(\"delta\").load(gold_path).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a3f130e-99d5-444c-b536-c3ce21cf1af4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Limpando o cache\n",
    "limpeza_cache(\n",
    "    df_cidade, df_cidade_gold, df_gold_ativos, df_gold_inativos,\n",
    "    df_modificados, df_modificados_inativos, df_pais_gold, \n",
    "    df_modificados_novos, df_novas_cidades, df_silver_gold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86507c0a-fc22-4591-8808-622eec56a020",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Dimensão - Clientes\n",
    "- Aplicar SCD2\n",
    "- Aplicar SK\n",
    "- Aplicar relação com Cidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10961b49-632d-4236-9182-c29753a514b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+------------------+--------------------+--------------------+-------+-----+---------+--------+\n|ClienteID|       NomeCliente|          Endereco|    DATA_ATUALIZACAO|             DataINI|DataFIM|Ativo|ClienteSK|CidadeSK|\n+---------+------------------+------------------+--------------------+--------------------+-------+-----+---------+--------+\n|      148|   Darrick H Kirby|     480 Oak Drive|2025-02-21 18:46:...|2025-02-21 18:46:...|   null| true|        1|      68|\n|      463|Bryon Q Montgomery|   914 Old Freeway|2025-02-21 18:46:...|2025-02-21 18:46:...|   null| true|        2|      86|\n|      471|  Preston Y Vargas|  76 Nobel Parkway|2025-02-21 18:46:...|2025-02-21 18:46:...|   null| true|        3|      11|\n|      496|      Leo S Hardin|77 Green Hague Way|2025-02-21 18:46:...|2025-02-21 18:46:...|   null| true|        4|      63|\n|      833|   Manuel W Rhodes|    18 Cowley Road|2025-02-21 18:46:...|2025-02-21 18:46:...|   null| true|        5|       1|\n+---------+------------------+------------------+--------------------+--------------------+-------+-----+---------+--------+\nonly showing top 5 rows\n\nroot\n |-- ClienteID: integer (nullable = true)\n |-- NomeCliente: string (nullable = true)\n |-- Endereco: string (nullable = true)\n |-- DATA_ATUALIZACAO: timestamp (nullable = true)\n |-- DataINI: timestamp (nullable = true)\n |-- DataFIM: timestamp (nullable = true)\n |-- Ativo: boolean (nullable = true)\n |-- ClienteSK: long (nullable = true)\n |-- CidadeSK: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "sv_file = f'{sv_dim_path}/CLIENTE'\n",
    "gd_file = f'{gd_dim_path}/CLIENTE'\n",
    "gd_cidade = f'{gd_dim_path}/CIDADE'\n",
    "\n",
    "# Carregamento de Cliente na Camada Silver\n",
    "df_cliente = spark.read.format(\"delta\").load(sv_file)\n",
    "\n",
    "# Procura de dados na camada Gold\n",
    "try:\n",
    "    df_cliente_gold = spark.read.format(\"delta\").load(gd_file)\n",
    "    ultimo_sk = df_cliente_gold.agg(max_(\"CidadeSK\")).collect()[0][0]\n",
    "    if ultimo_sk is None:\n",
    "        ultimo_sk = 0\n",
    "except:\n",
    "    # Caso ainda não haja dados na Gold, cria-se o formato de tabela vazia\n",
    "    # já inserindo a SK de Cidade e a SK estrangeira de País\n",
    "    schema = df_cliente.schema \\\n",
    "                      .add(\"DataINI\", \"timestamp\") \\\n",
    "                      .add(\"DataFIM\", \"timestamp\") \\\n",
    "                      .add(\"Ativo\", \"boolean\") \\\n",
    "                      .add(\"ClienteSK\", \"long\") \\\n",
    "                      .add(\"CidadeSK\", \"long\")\n",
    "    df_cliente_gold = spark.createDataFrame([], schema)\n",
    "    ultimo_sk = 0\n",
    "\n",
    "\n",
    "# Ajustando a tipagem da coluna de SK nos Dataframes\n",
    "df_cliente = df_cliente.withColumn(\"ClienteSK\", lit(None).cast(\"long\"))\n",
    "df_cliente_gold = df_cliente_gold.withColumn(\"ClienteSK\", col(\"ClienteSK\").cast(\"long\"))\n",
    "\n",
    "# Trazendo SKs e IDs de Cidade da Gold\n",
    "df_cidade_gold = spark.read.format(\"delta\") \\\n",
    "    .load(gd_cidade).filter(col(\"Ativo\") == True) \\\n",
    "    .select(\"CidadeID\", \"CidadeSK\")\n",
    "\n",
    "# Fazendo a junção entre os clientes da Silver e as cidades da Gold\n",
    "df_cliente = df_cliente.join(df_cidade_gold, \"CidadeID\", \"left\")\n",
    "\n",
    "# Certifica a existência da coluna CidadeID nos dados da Gold\n",
    "if \"CidadeID\" not in df_cliente_gold.columns:\n",
    "    df_cliente_gold.withColumn(\"CidadeID\", lit(None).cast(dtype))\n",
    "\n",
    "# Filtra registros ativos e inativos no caso de já existirem registros em Gold\n",
    "df_gold_ativos = df_cliente_gold.filter(col(\"Ativo\") == True)\n",
    "df_gold_inativos = df_cliente_gold.filter(col(\"Ativo\") == False)\n",
    "\n",
    "# Juntando registros ativos já existentes na Gold com os vindos da Silver para achar mudanças\n",
    "df_silver_gold = df_cliente.alias(\"silver\").join(df_gold_ativos.alias(\"gold\"), \"ClienteID\", \"left\")\n",
    "\n",
    "# Checando se algum registro existente na gold foi modificado por comparação Silver - Gold\n",
    "df_modificados = df_silver_gold.filter(\n",
    "    (col(\"silver.NomeCliente\") != col(\"gold.NomeCliente\")) |\n",
    "    (col(\"silver.Endereco\") != col(\"gold.Endereco\")) |\n",
    "    (col(\"silver.CidadeSK\") != col(\"gold.CidadeSK\"))\n",
    ")\n",
    "\n",
    "# Marca os registros antigos da Gold que foram modificados como INATIVO (False)\n",
    "df_modificados_inativos = df_modificados.select(\n",
    "    col(\"gold.ClienteID\"),\n",
    "    col(\"gold.ClienteSK\"),\n",
    "    col(\"gold.NomeCliente\"),\n",
    "    col(\"gold.Endereco\"),\n",
    "    col(\"gold.CidadeSK\"),\n",
    "    col(\"gold.CidadeID\"),\n",
    "    col(\"gold.DATA_ATUALIZACAO\"),\n",
    "    col(\"gold.DataINI\"),\n",
    "    current_timestamp().alias(\"DataFIM\"),\n",
    "    lit(False).alias(\"Ativo\")\n",
    ")\n",
    "\n",
    "# Inclusão das SKs nos registros novos que vem da Silver e ATIVAÇÃO dos registros como vigentes (True)\n",
    "df_modificados_novos = df_modificados.select(\n",
    "    col(\"silver.ClienteID\"),\n",
    "    (monotonically_increasing_id() + ultimo_sk + 1).cast(\"long\").alias(\"ClienteSK\"),\n",
    "    col(\"silver.NomeCliente\"),\n",
    "    col(\"silver.Endereco\"),\n",
    "    col(\"silver.CidadeSK\"),\n",
    "    col(\"silver.CidadeID\"),\n",
    "    col(\"silver.DATA_ATUALIZACAO\"),\n",
    "    col(\"silver.DATA_ATUALIZACAO\").alias(\"DataINI\"),\n",
    "    lit(None).cast(\"timestamp\").alias(\"DataFIM\"),\n",
    "    lit(True).alias(\"Ativo\")\n",
    ")\n",
    "\n",
    "# Contando quantos SKs já temos até o momento (juntando os ativos e os das modificações)\n",
    "total_sks = ultimo_sk + df_gold_ativos.count() + df_modificados_novos.count()\n",
    "\n",
    "# Coletando os registros novos que não estavam em Gold ainda e inserindo data e SKs de acordo com a contagem\n",
    "df_novos_clientes = df_cliente.alias(\"silver\") \\\n",
    "    .join(df_gold_ativos.alias(\"gold\"), \"ClienteID\", \"left_anti\") \\\n",
    "    .withColumn(\"DataINI\", col(\"silver.DATA_ATUALIZACAO\")) \\\n",
    "    .withColumn(\"DataFIM\", lit(None).cast(\"timestamp\")) \\\n",
    "    .withColumn(\"Ativo\", lit(True)) \\\n",
    "    .withColumn(\"ClienteSK\", (monotonically_increasing_id() + total_sks + 1).cast(\"long\"))\n",
    "\n",
    "# Pegando a lista de ClienteIDs dos dados modificados\n",
    "ids_modificados = df_modificados.select(\"ClienteID\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# União dos registros atualizados (inativos e novos ativos) da Gold e novos registros vindos da Silver\n",
    "df_cliente_gold = df_gold_inativos \\\n",
    "    .unionByName(df_modificados_inativos) \\\n",
    "    .unionByName(df_modificados_novos) \\\n",
    "    .unionByName(df_novos_clientes) \\\n",
    "    .unionByName(df_gold_ativos.filter(~col(\"ClienteID\").isin(ids_modificados)))\n",
    "\n",
    "# Dropando a coluna PaisID da tabela final\n",
    "df_cliente_gold = df_cliente_gold.drop(\"CidadeID\")\n",
    "\n",
    "# Verificando schema antes de salvar\n",
    "df_cliente_gold.show(5)\n",
    "df_cliente_gold.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc6ff443-93be-49b5-9902-f57a81c108b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela salva em /mnt/desafio-dwe-25/lhdw/gold/dim/CLIENTE:\n+---------+---------------+--------------------+--------------------+--------------------+-------+-----+---------+--------+\n|ClienteID|    NomeCliente|            Endereco|    DATA_ATUALIZACAO|             DataINI|DataFIM|Ativo|ClienteSK|CidadeSK|\n+---------+---------------+--------------------+--------------------+--------------------+-------+-----+---------+--------+\n|        1|Stefanie Y Frye|       97 Oak Avenue|2025-02-21 18:46:...|2025-02-21 18:46:...|   null| true|        1|      88|\n|        2|  Sandy T Kirby|52 White First Fr...|2025-02-21 18:46:...|2025-02-21 18:46:...|   null| true|        2|      30|\n|        3|    Lee T Zhang|921 White Fabien ...|2025-02-21 18:46:...|2025-02-21 18:46:...|   null| true|        3|      47|\n|        4| Regina S Avery|       75 Old Avenue|2025-02-21 18:46:...|2025-02-21 18:46:...|   null| true|        4|      26|\n|        5|Daniel S Mccann|283 South Green H...|2025-02-21 18:46:...|2025-02-21 18:46:...|   null| true|        5|      87|\n+---------+---------------+--------------------+--------------------+--------------------+-------+-----+---------+--------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "gold_path = f'{gd_dim_path}/CLIENTE'\n",
    "\n",
    "# Salvando os arquivos na Gold\n",
    "df_cliente_gold.write.format(\"delta\").mode(\"overwrite\").save(gold_path)\n",
    "\n",
    "# Verificação dos resultados\n",
    "print(f'Tabela salva em {gold_path}:')\n",
    "spark.read.format(\"delta\").load(gold_path).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d829aa06-a041-4812-baac-e4aceaf230db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Limpando o cache\n",
    "limpeza_cache(\n",
    "    df_cidade_gold, df_cliente, df_cliente_gold,\n",
    "    df_gold_ativos, df_gold_inativos, df_modificados,\n",
    "    df_modificados_inativos, df_modificados_novos,\n",
    "    df_novos_clientes, df_silver_gold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bb83146-6926-4102-bc52-6c8cfda81a16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Fato - Vendas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36defd01-c410-49be-af49-c691964aa022",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------+------------------+----------+--------------------+----+---+---------+----------+---------+\n|VendasID|Quantidade|Desconto|        PrecoTotal| DataVenda|    DATA_ATUALIZACAO| ANO|MES|ClienteSK|VendedorSK|ProdutoSK|\n+--------+----------+--------+------------------+----------+--------------------+----+---+---------+----------+---------+\n| 1447191|        13|     0.0|          826.1812|2018-02-07|2025-02-21 18:48:...|2018|  2|    48640|        21|      155|\n|  233900|         1|     0.2|49.759440000000005|2018-02-07|2025-02-21 18:48:...|2018|  2|     2782|        19|       96|\n|  930189|         4|     0.0|          275.5156|2018-02-07|2025-02-21 18:48:...|2018|  2|    15286|        23|      105|\n| 4792802|         7|     0.0|          132.8299|2018-02-07|2025-02-21 18:48:...|2018|  2|    26268|        10|      205|\n| 6576409|        17|     0.0|492.82829999999996|2018-02-07|2025-02-21 18:48:...|2018|  2|    65099|        17|      338|\n+--------+----------+--------+------------------+----------+--------------------+----+---+---------+----------+---------+\nonly showing top 5 rows\n\nroot\n |-- VendasID: integer (nullable = true)\n |-- Quantidade: integer (nullable = true)\n |-- Desconto: double (nullable = true)\n |-- PrecoTotal: double (nullable = true)\n |-- DataVenda: date (nullable = true)\n |-- DATA_ATUALIZACAO: timestamp (nullable = true)\n |-- ANO: integer (nullable = true)\n |-- MES: integer (nullable = true)\n |-- ClienteSK: long (nullable = true)\n |-- VendedorSK: long (nullable = true)\n |-- ProdutoSK: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "sv_file = f'{sv_fato_path}/VENDAS'\n",
    "gd_file = f'{sv_fato_path}/VENDAS'\n",
    "\n",
    "gd_cliente = f'{gd_dim_path}/CLIENTE'\n",
    "gd_vendedor = f'{gd_dim_path}/VENDEDOR'\n",
    "gd_produto = f'{gd_dim_path}/PRODUTO'\n",
    "\n",
    "# Carregamento da Fato Vendas na Camada Silver\n",
    "df_vendas = spark.read.format(\"delta\").load(sv_file)\n",
    "\n",
    "# Carregando as dimensões Cliente, Vendedor e Produto\n",
    "df_cliente_gold = spark.read.format(\"delta\").load(gd_cliente).filter(col(\"Ativo\") == True)\n",
    "df_vendedor_gold = spark.read.format(\"delta\").load(gd_vendedor).filter(col(\"Ativo\") == True)\n",
    "df_produto_gold = spark.read.format(\"delta\").load(gd_produto).filter(col(\"Ativo\") == True)\n",
    "\n",
    "# Carregando a fato silver com as referências de Cliente, Vendedor e Produto\n",
    "df_silver_fato = df_vendas \\\n",
    "    .join(df_cliente_gold.select(\"ClienteID\", \"ClienteSK\"), \"ClienteID\", \"left\") \\\n",
    "    .join(df_vendedor_gold.select(\"VendedorID\", \"VendedorSK\"), \"VendedorID\", \"left\") \\\n",
    "    .join(df_produto_gold.select(\"ProdutoID\", \"ProdutoSK\"), \"ProdutoID\", \"left\")\n",
    "\n",
    "# Remover as colunas de IDs e manter as SKs\n",
    "df_silver_fato = df_silver_fato.drop(\"ClienteID\", \"VendedorID\", \"ProdutoID\") \\\n",
    "    .withColumnRenamed(\"ClienteSK\", \"ClienteSK\") \\\n",
    "    .withColumnRenamed(\"VendedorSK\", \"VendedorSK\") \\\n",
    "    .withColumnRenamed(\"ProdutoSK\", \"ProdutoSK\")\n",
    "\n",
    "# Buscando a ultima venda armazenada na Gold\n",
    "try:\n",
    "    df_vendas_gold = spark.read.format(\"delta\").load(gd_file)\n",
    "    ultima_venda = df_vendas_gold.agg(max_(\"VendasID\")).collect()[0][0]\n",
    "    if ultima_venda is None:\n",
    "        ultima_venda = 0\n",
    "except:\n",
    "    ultima_venda = 0\n",
    "\n",
    "# Separando os registros novos de venda da Silver que irão pra Gold\n",
    "df_novas_vendas = df_silver_fato.filter(col(\"VendasID\") > ultima_venda)\n",
    "\n",
    "df_novas_vendas.show(5)\n",
    "df_novas_vendas.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd1be6b6-a81e-4c10-9122-09e11c06ca52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela salva em /mnt/desafio-dwe-25/lhdw/gold/fato/VENDAS:\n+--------+----------+--------+------------------+----------+--------------------+----+---+---------+----------+---------+\n|VendasID|Quantidade|Desconto|        PrecoTotal| DataVenda|    DATA_ATUALIZACAO| ANO|MES|ClienteSK|VendedorSK|ProdutoSK|\n+--------+----------+--------+------------------+----------+--------------------+----+---+---------+----------+---------+\n| 1447191|        13|     0.0|          826.1812|2018-02-07|2025-02-21 18:48:...|2018|  2|    48640|        21|      155|\n|  233900|         1|     0.2|49.759440000000005|2018-02-07|2025-02-21 18:48:...|2018|  2|     2782|        19|       96|\n|  930189|         4|     0.0|          275.5156|2018-02-07|2025-02-21 18:48:...|2018|  2|    15286|        23|      105|\n| 4792802|         7|     0.0|          132.8299|2018-02-07|2025-02-21 18:48:...|2018|  2|    26268|        10|      205|\n| 6576409|        17|     0.0|492.82829999999996|2018-02-07|2025-02-21 18:48:...|2018|  2|    65099|        17|      338|\n+--------+----------+--------+------------------+----------+--------------------+----+---+---------+----------+---------+\nonly showing top 5 rows\n\nNúmero de registros na tabela Delta: 965446\n"
     ]
    }
   ],
   "source": [
    "gold_path = f'{gd_fato_path}/VENDAS'\n",
    "\n",
    "# Salvando os arquivos na Gold\n",
    "df_novas_vendas.write.partitionBy(\"ANO\", \"MES\").format(\"delta\").mode(\"append\").save(gold_path)\n",
    "\n",
    "# Verificação dos resultados\n",
    "print(f'Tabela salva em {gold_path}:')\n",
    "gold_fato_vendas = spark.read.format(\"delta\").load(gold_path)\n",
    "gold_fato_vendas.show(5)\n",
    "print(f\"Número de registros na tabela Delta: {gold_fato_vendas.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a99da3c5-d864-4566-b944-85773bd21a49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Limpeza de cache\n",
    "limpeza_cache(\n",
    "    df_cliente_gold, df_novas_vendas,\n",
    "    df_produto_gold, df_silver_fato,\n",
    "    df_vendas, df_vendas_gold, df_vendedor_gold\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "004 - Transformação Camada Gold",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
